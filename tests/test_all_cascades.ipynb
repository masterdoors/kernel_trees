{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57bc4660",
   "metadata": {},
   "source": [
    "# PRIMARY SETUPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1307b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd deepforest && pip install --verbose -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc07e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "'''\n",
    "Created on 21 мая 2016 г.\n",
    "\n",
    "@author: keen\n",
    "'''\n",
    "\n",
    "from sklearn import datasets\n",
    "import pickle\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import preprocessing\n",
    "from numpy import ndarray\n",
    "from numpy import asarray\n",
    "from numpy.random import randint as rint\n",
    "import datetime\n",
    "from random import randint\n",
    "import numpy\n",
    "from sklearn.datasets import fetch_openml\n",
    "#from sklearn.svm import SVC\n",
    "import CO2_tree as co2t\n",
    "import CO2_forest as co2f\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 5000\n",
    "TEST_SIZE = 1000\n",
    "SHAKE = False\n",
    "NJOBS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ffad3",
   "metadata": {},
   "source": [
    "# Load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfffdac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f008235",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556f8fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, Y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "x = preprocessing.normalize(x, copy=False, axis = 0)\n",
    "Y = Y.astype(int) + 1\n",
    "\n",
    "x_train = x[:60000,:]\n",
    "x_validate = x[60000:,:]\n",
    "\n",
    "Y_train = Y[:60000]#[:6000]\n",
    "Y_validate = Y[60000:]#[:3000]\n",
    "\n",
    "data['MNIST'] = [[x_train,Y_train],[x_validate,Y_validate],(28,28,1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac559bf9",
   "metadata": {},
   "source": [
    "## USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926117a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, Y = fetch_openml(\"USPS\", version=1, return_X_y=True, as_frame=False)\n",
    "x = preprocessing.normalize(x, copy=False, axis = 0)\n",
    "Y = Y.astype(int) + 1\n",
    "\n",
    "x_train = x[:7291,:]\n",
    "x_validate = x[7291:,:]\n",
    "\n",
    "Y_train = Y[:7291]#[:6000]\n",
    "Y_validate = Y[7291:]#[:3000]\n",
    "data['USPS'] = [[x_train,Y_train],[x_validate,Y_validate],(16,16,1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30655cd",
   "metadata": {},
   "source": [
    "## CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a382aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, Y = fetch_openml(\"CIFAR_10\", version=1, return_X_y=True, as_frame=False)\n",
    "x = preprocessing.normalize(x, copy=False, axis = 0)\n",
    "Y = Y.astype(int) + 1\n",
    "\n",
    "x_train = x[:50000,:]\n",
    "x_validate = x[50000:,:]\n",
    "\n",
    "Y_train = Y[:50000]#[:6000]\n",
    "Y_validate = Y[50000:]#[:3000]\n",
    "data['CIFAR'] = [[x_train,Y_train],[x_validate,Y_validate],(32,32,3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932f541c",
   "metadata": {},
   "source": [
    "## LETTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d5368",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, Y = fetch_openml(\"letter\", version=1, return_X_y=True, as_frame=False)\n",
    "x = preprocessing.normalize(x, copy=False, axis = 0)\n",
    "Y = preprocessing.LabelEncoder().fit_transform(Y).astype(int) + 1\n",
    "\n",
    "x_train = x[:15000,:]\n",
    "x_validate = x[15000:,:]\n",
    "\n",
    "Y_train = Y[:15000]#[:6000]\n",
    "Y_validate = Y[15000:]#[:3000]\n",
    "data['letter'] = [[x_train,Y_train],[x_validate,Y_validate],(4,4,1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab07ace",
   "metadata": {},
   "source": [
    "## SATIMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0666204",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, Y = fetch_openml(\"satimage\", version=1, return_X_y=True, as_frame=False)\n",
    "x = preprocessing.normalize(x, copy=False, axis = 0)\n",
    "Y =  preprocessing.LabelEncoder().fit_transform(Y).astype(int) + 1\n",
    "\n",
    "x_train = x[:5000,:]\n",
    "x_validate = x[5000:,:]\n",
    "\n",
    "Y_train = Y[:5000]#[:6000]\n",
    "Y_validate = Y[5000:]#[:3000]\n",
    "data['satimage'] = [[x_train,Y_train],[x_validate,Y_validate],(6,6,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c76e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da79e1a",
   "metadata": {},
   "source": [
    "# DEFINE ALL POSSIBLE TEST SCENARIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d975754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepforest import CascadeForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "TREE_D = [4,6,8,10]\n",
    "TREE_F = [0.1,0.2,0.3,0.4,0.5,0.6,0.7]\n",
    "\n",
    "\n",
    "KERNEL = ['linear','gaussian']\n",
    "KERNEL_PRUNE = [True,False]\n",
    "KERNEL_PRUNE = [True]\n",
    "KERNEL_PRUNE_C = [10]\n",
    "KERNEL_PRUNE_N = [0.1]\n",
    "\n",
    "n_estimators = 2\n",
    "\n",
    "estimators=[]\n",
    "\n",
    "#for rf_ratio in [0.,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "for rf_ratio in [0.]:\n",
    "    for t in TREE_D:\n",
    "        for f in TREE_F:\n",
    "            tmp = []\n",
    "            tmp.append('RF')\n",
    "            tmp.append(t)\n",
    "            tmp.append(f)\n",
    "            tmp.append([RandomForestClassifier(max_depth=t,max_features=f,random_state=i,n_jobs=NJOBS,n_estimators=30) for i in range(n_estimators)])\n",
    "            estimators.append(tmp)  \n",
    "\n",
    "            for k in KERNEL:\n",
    "                for pr in KERNEL_PRUNE:\n",
    "                    if pr:\n",
    "                        for c in KERNEL_PRUNE_C:\n",
    "                            for n in KERNEL_PRUNE_N:\n",
    "                                tmp = []\n",
    "                                tmp.append(rf_ratio)\n",
    "                                tmp.append('KF')\n",
    "                                tmp.append(t)\n",
    "                                tmp.append(f)\n",
    "                                tmp.append(k)\n",
    "                                tmp.append(\"Pruned\")\n",
    "                                tmp.append(c)\n",
    "                                tmp.append(n)\n",
    "                                tmp.append([co2f.CO2_forest(C=5500, min_samples_leaf=4,dual=False,tol = 0.0001,max_iter=1000,kernel=k,max_deth=t,n_jobs=NJOBS,sample_ratio=1.0, feature_ratio = f,n_estimators=30,gamma=100,dropout_low=0.0,dropout_high=1.0,noise=0.,cov_dr=0.,criteria='gain',reinforced = True, prune_level = n,reC=c,univariate_ratio = rf_ratio) for i in range(int(n_estimators))])                            \n",
    "                                #tmp[len(tmp) - 1] += [RandomForestClassifier(max_depth=t,max_features=f,random_state=i,n_jobs=NJOBS,n_estimators=10) for i in range(int(n_estimators * rf_ratio))]\n",
    "\n",
    "                                estimators.append(tmp) \n",
    "                    else:\n",
    "                        tmp = []\n",
    "                        tmp.append(rf_ratio)\n",
    "\n",
    "                        tmp.append('KF')\n",
    "                        tmp.append(t)\n",
    "                        tmp.append(f)\n",
    "                        tmp.append(k)\n",
    "                        tmp.append(\"Not pruned\") \n",
    "                        tmp.append([co2f.CO2_forest(C=5500, min_samples_leaf=4,dual=False,tol = 0.0001,max_iter=1000,kernel=k,max_deth=t,n_jobs=NJOBS,sample_ratio=1.0, feature_ratio = f,n_estimators=30,gamma=100,dropout_low=0.0,dropout_high=1.0,noise=0.,cov_dr=0.,criteria='gain',univariate_ratio = rf_ratio) for i in range(int(n_estimators))])                            \n",
    "                        #tmp[len(tmp) - 1] += [RandomForestClassifier(max_depth=t,max_features=f,random_state=i,n_jobs=NJOBS,n_estimators=10) for i in range(int(n_estimators * rf_ratio))]\n",
    "\n",
    "                        estimators.append(tmp)  \n",
    "                    \n",
    "WIN = [True,False]\n",
    "\n",
    "DS_WIN_SZ = {\n",
    "    'MNIST':[10],\n",
    "    'USPS':[6],\n",
    "    'letter':[4],\n",
    "    'CIFAR':[10],\n",
    "    'satimage':[6]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd48b01",
   "metadata": {},
   "source": [
    "# Do tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b5d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "def LOG(str_):\n",
    "    with open(\"log_2023_diffrent_forests3.txt\", \"a\") as f:\n",
    "        if str_ != '\\n':\n",
    "            f.write(str(str_) + \";\")\n",
    "        else:    \n",
    "            f.write(str_)\n",
    "            \n",
    "for TRAIN_SIZE in [5000]:\n",
    "    for TEST_SIZE in [1000]:\n",
    "        for d in data:\n",
    "            x_train = data[d][0][0]\n",
    "            Y_train = data[d][0][1]\n",
    "            x_validate = data[d][1][0]\n",
    "            Y_validate = data[d][1][1]\n",
    "            if SHAKE:\n",
    "                tr_idxs = numpy.random.permutation(x_train.shape[0])[:TRAIN_SIZE]         \n",
    "                tst_idxs = numpy.random.permutation(x_validate.shape[0])[:TEST_SIZE]         \n",
    "                x_train = x_train[tr_idxs]\n",
    "                Y_train = Y_train[tr_idxs]\n",
    "                x_validate = x_validate[tst_idxs]\n",
    "                Y_validate = Y_validate[tst_idxs]\n",
    "\n",
    "            if data[d][2][2] > 1:\n",
    "                x_train = x_train.reshape((data[d][2][2],-1,data[d][2][0],data[d][2][1]))\n",
    "                x_validate = x_validate.reshape((data[d][2][2],-1,data[d][2][0],data[d][2][1]))\n",
    "            else:\n",
    "                x_train = x_train.reshape((-1,data[d][2][0],data[d][2][1]))\n",
    "                x_validate = x_validate.reshape((-1,data[d][2][0],data[d][2][1]))\n",
    "\n",
    "            for w in WIN:\n",
    "                for wss in DS_WIN_SZ[d]:\n",
    "                    for e_idx,e in enumerate(estimators):\n",
    "                        est = e[len(e) - 1]    \n",
    "                        model = CascadeForestClassifier(max_layers=3)\n",
    "                        model.set_estimator(est)   \n",
    "                        start_time = time.time()\n",
    "                        if w and data[d][2][0] < wss:\n",
    "                            model.set_win([wss,-1,-1],[2,1,1],[data[d][2][0],1,1],[data[d][2][1],1,1],[0,0,0],[2,0,0],[False,True,True])\n",
    "                            model.fit(x_train, Y_train)#\n",
    "                            pred = model.predict(x_validate)\n",
    "                        else: \n",
    "                            model.fit(x_train.reshape(-1,data[d][2][0]*data[d][2][1]*data[d][2][2]), Y_train)#\n",
    "                            pred = model.predict(x_validate.reshape(-1,data[d][2][0]*data[d][2][1]*data[d][2][2]))\n",
    "\n",
    "                        for i in range(len(e) - 1):\n",
    "                            LOG(e[i])                    \n",
    "                        LOG(d)\n",
    "                        LOG(time.time() - start_time)\n",
    "                        LOG(TRAIN_SIZE)\n",
    "                        LOG(TEST_SIZE)\n",
    "                        print (d,w,wss,e[:len(e)-1])\n",
    "\n",
    "\n",
    "                        LOG(precision_score(Y_validate, pred,average='macro'))\n",
    "                        LOG(recall_score(Y_validate, pred,average='macro'))                        \n",
    "                        LOG(accuracy_score(Y_validate, pred))     \n",
    "\n",
    "                        LOG('\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
