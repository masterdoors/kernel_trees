{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c7231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "'''\n",
    "Created on 21 мая 2016 г.\n",
    "\n",
    "@author: keen\n",
    "'''\n",
    "\n",
    "from sklearn import datasets\n",
    "import pickle\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import preprocessing\n",
    "from numpy import ndarray\n",
    "from numpy import asarray\n",
    "from numpy.random import randint as rint\n",
    "import datetime\n",
    "from random import randint\n",
    "import numpy\n",
    "import CO2_tree_reg as co2t\n",
    "import CO2_forest_reg as co2f\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682bfe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_train = []\n",
    "Y_train = []\n",
    "for ds in os.listdir(\"processed/train\"):\n",
    "    ds_name = os.path.join(\"processed/train\",ds)\n",
    "    data = None\n",
    "    labels = None\n",
    "    for f in os.listdir(ds_name):\n",
    "        filename = os.path.join(ds_name,f)  \n",
    "        if filename.find(\"data\") > -1:\n",
    "            data = numpy.nan_to_num(numpy.load(filename),posinf=0,neginf=0)\n",
    "        else:                   \n",
    "            labels = numpy.nan_to_num(numpy.load(filename),posinf=0,neginf=0)\n",
    "            print (filename,labels.mean())\n",
    "    if data is not None:     \n",
    "        x_train.append(data.astype(numpy.float64)[:1000])\n",
    "        Y_train.append(labels.mean(axis=1).mean(axis=1).astype(float).reshape(-1,1)[:1000])\n",
    "        \n",
    "x_validate = []\n",
    "Y_validate = []\n",
    "for ds in os.listdir(\"processed/outumn\"):\n",
    "    ds_name = os.path.join(\"processed/outumn\",ds)\n",
    "    data = None\n",
    "    labels = None\n",
    "    for f in os.listdir(ds_name):\n",
    "        filename = os.path.join(ds_name,f)  \n",
    "        if filename.find(\"data\") > -1:\n",
    "            data = numpy.nan_to_num(numpy.load(filename),posinf=0,neginf=0)\n",
    "        else:                   \n",
    "            labels = numpy.nan_to_num(numpy.load(filename),posinf=0,neginf=0)\n",
    "            print (filename,labels.mean())\n",
    "    if data is not None:        \n",
    "        x_validate.append(data.astype(numpy.float64)[:1000])\n",
    "        Y_validate.append(labels.mean(axis=1).mean(axis=1).astype(float).reshape(-1,1)[:1000])\n",
    "\n",
    "data={}\n",
    "data['NVDI'] = [[numpy.vstack(x_train),numpy.vstack(Y_train)],[numpy.vstack(x_validate),numpy.vstack(Y_validate)],(228,228,3)]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55cc36b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={}\n",
    "data['NVDI'] = [[[],[]],[[],[]],(228,228,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa05583",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 1000\n",
    "TEST_SIZE = 1000\n",
    "SHAKE = True\n",
    "NJOBS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30f58fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepforest import CascadeForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "TREE_D = [4]\n",
    "TREE_F = [0.02]\n",
    "\n",
    "\n",
    "KERNEL = ['linear']\n",
    "KERNEL_PRUNE = [True,False]\n",
    "KERNEL_PRUNE_C = [1]\n",
    "KERNEL_PRUNE_N = [0.1]\n",
    "\n",
    "n_estimators = 2\n",
    "\n",
    "estimators=[]\n",
    "\n",
    "for t in TREE_D:\n",
    "    for f in TREE_F:\n",
    "        tmp = []\n",
    "        tmp.append('RF')\n",
    "        tmp.append(t)\n",
    "        tmp.append(f)\n",
    "        tmp.append([RandomForestRegressor(max_depth=t,max_features=f,random_state=i,n_jobs=NJOBS) for i in range(n_estimators)])\n",
    "        estimators.append(tmp)  \n",
    "        \n",
    "        for k in KERNEL:\n",
    "            for pr in KERNEL_PRUNE:\n",
    "                if pr:\n",
    "                    for c in KERNEL_PRUNE_C:\n",
    "                        for n in KERNEL_PRUNE_N:\n",
    "                            tmp = []\n",
    "                            tmp.append('KF')\n",
    "                            tmp.append(t)\n",
    "                            tmp.append(f)\n",
    "                            tmp.append(k)\n",
    "                            tmp.append(\"Pruned\")\n",
    "                            tmp.append(c)\n",
    "                            tmp.append(n)\n",
    "                            tmp.append([co2f.CO2_forestReg(C=5500, min_samples_leaf=4,dual=False,tol = 0.0001,max_iter=10000,kernel=k,max_deth=t,n_jobs=NJOBS,sample_ratio=1.0, feature_ratio = f,n_estimators=30,gamma=100,dropout_low=0.0,dropout_high=1.0,noise=0.,cov_dr=0.,reinforced = True, prune_level = n,reC=c) for i in range(n_estimators)])                            \n",
    "                            estimators.append(tmp) \n",
    "                    else:\n",
    "                        tmp = []\n",
    "\n",
    "                        tmp.append('KF')\n",
    "                        tmp.append(t)\n",
    "                        tmp.append(f)\n",
    "                        tmp.append(k)\n",
    "                        tmp.append(\"Not pruned\") \n",
    "                        tmp.append([co2f.CO2_forestReg(C=5500, min_samples_leaf=4,dual=False,tol = 0.0001,max_iter=10000,kernel=k,max_deth=t,n_jobs=NJOBS,sample_ratio=1.0, feature_ratio = f,n_estimators=30,gamma=100,dropout_low=0.0,dropout_high=1.0,noise=0.,cov_dr=0.) for i in range(n_estimators)])                            \n",
    "\n",
    "                        estimators.append(tmp)  \n",
    "                    \n",
    "WIN = [False]\n",
    "\n",
    "DS_WIN_SZ = {\n",
    "    'NVDI':[32],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b71814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-24 18:47:46.160] Start to fit the model:\n",
      "[2022-08-24 18:47:46.160] Fitting cascade layer = 0 \n",
      "[2022-08-24 18:48:26.147] layer = 0  | Val MSE = 0.00896 | Elapsed = 39.987 s\n",
      "[2022-08-24 18:48:26.630] Fitting cascade layer = 1 \n",
      "[2022-08-24 18:49:06.760] layer = 1  | Val MSE = 0.00877 | Elapsed = 40.131 s\n",
      "[2022-08-24 18:49:07.254] Fitting cascade layer = 2 \n",
      "[2022-08-24 18:49:47.325] layer = 2  | Val MSE = 0.00883 | Elapsed = 40.071 s\n",
      "[2022-08-24 18:49:47.325] Early stopping counter: 1 out of 2\n",
      "[2022-08-24 18:49:47.325] Reaching the maximum number of layers: 3\n",
      "[2022-08-24 18:49:47.473] Start to evalute the model:\n",
      "[2022-08-24 18:49:47.955] Evaluating cascade layer = 0 \n",
      "[2022-08-24 18:49:50.587] Evaluating cascade layer = 1 \n",
      "[2022-08-24 18:49:53.289] Evaluating cascade layer = 2 \n",
      "[2022-08-24 18:49:56.077] Start to evalute the model:\n",
      "[2022-08-24 18:49:56.499] Evaluating cascade layer = 0 \n",
      "[2022-08-24 18:49:59.150] Evaluating cascade layer = 1 \n",
      "[2022-08-24 18:50:01.850] Evaluating cascade layer = 2 \n",
      "NVDI False 1 ['RF', 4, 0.02]\n",
      "[2022-08-24 18:50:04.745] Start to fit the model:\n",
      "[2022-08-24 18:50:04.745] Fitting cascade layer = 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-24 20:50:08.695] layer = 0  | Val MSE = 0.00499 | Elapsed = 7203.949 s\n",
      "[2022-08-24 20:50:09.159] Fitting cascade layer = 1 \n"
     ]
    }
   ],
   "source": [
    "from os.path import exists \n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def LOG(str_):\n",
    "    with open(\"log_nvdi_sp_out.txt\", \"a\") as f:\n",
    "        if str_ != '\\n':\n",
    "            f.write(str(str_) + \";\")\n",
    "        else:    \n",
    "            f.write(str_)\n",
    "            \n",
    "def INLOG(str_):\n",
    "    if exists(\"log_nvdi_sp_out.txt\"):\n",
    "        with open(\"log_nvdi_sp_out.txt\",'r') as f:\n",
    "            log = f.read()\n",
    "        return log.find(str_) > -1\n",
    "    return False            \n",
    "            \n",
    "for d in data:\n",
    "    x_train = data[d][0][0]\n",
    "    Y_train = data[d][0][1]\n",
    "    x_validate = data[d][1][0]\n",
    "    Y_validate = data[d][1][1]\n",
    "    if SHAKE:\n",
    "        if exists(d + \"_train_data.npy\"): \n",
    "            x_train = numpy.load(d + \"_train_data.npy\")\n",
    "            Y_train = numpy.load(d + \"_train_labels.npy\")\n",
    "            x_validate_sp = numpy.load(d + \"_test_data_sp.npy\")\n",
    "            Y_validate_sp = numpy.load(d + \"_test_labels_sp.npy\")\n",
    "            x_validate_out = numpy.load(d + \"_test_data_out.npy\")\n",
    "            Y_validate_out = numpy.load(d + \"_test_labels_out.npy\")\n",
    "            \n",
    "        else:         \n",
    "            tr_idxs = numpy.random.permutation(x_train.shape[0])[:TRAIN_SIZE]         \n",
    "            tst_idxs = numpy.random.permutation(x_validate.shape[0])[:TEST_SIZE]         \n",
    "            x_train = x_train[tr_idxs]\n",
    "            Y_train = Y_train[tr_idxs]\n",
    "            x_validate = x_validate[tst_idxs]\n",
    "            Y_validate = Y_validate[tst_idxs]\n",
    "\n",
    "            numpy.save(d + \"_train_data\",x_train)\n",
    "            numpy.save(d + \"_train_labels\",Y_train)\n",
    "            numpy.save(d + \"_test_data_out\",x_validate)\n",
    "            numpy.save(d + \"_test_labels_out\",Y_validate)\n",
    "            break\n",
    "        \n",
    "    if data[d][2][2] > 1:\n",
    "        x_train = x_train.reshape((data[d][2][2],-1,data[d][2][0],data[d][2][1]))\n",
    "        x_validate_sp = x_validate_sp.reshape((data[d][2][2],-1,data[d][2][0],data[d][2][1]))\n",
    "        x_validate_out = x_validate_out.reshape((data[d][2][2],-1,data[d][2][0],data[d][2][1]))        \n",
    "    else:\n",
    "        x_train = x_train.reshape((-1,data[d][2][0],data[d][2][1]))\n",
    "        x_validate_sp = x_validate_sp.reshape((-1,data[d][2][0],data[d][2][1]))\n",
    "        x_validate_out = x_validate_out.reshape((-1,data[d][2][0],data[d][2][1]))\n",
    "        \n",
    "    for w in WIN:\n",
    "        if w:\n",
    "            wss_ = DS_WIN_SZ[d]\n",
    "        else:\n",
    "            wss_ = [1]\n",
    "        for wss in wss_:\n",
    "            for e_idx,e in enumerate(estimators):\n",
    "                est = e[len(e) - 1]\n",
    "                \n",
    "                l = d + \";\"\n",
    "                l += str(w) + \";\"\n",
    "                l += str(wss) + \";\" \n",
    "                for i in range(len(e) - 1):\n",
    "                    l += str(e[i]) + \";\" \n",
    "\n",
    "                if not INLOG(l):                \n",
    "                    model = CascadeForestRegressor(max_layers=3)\n",
    "                    model.set_estimator(est)                    \n",
    "                    if w and data[d][2][0] < wss:\n",
    "                        model.set_win([wss,-1,-1],[4,1,1],[data[d][2][0],1,1],[data[d][2][1],1,1],[0,0,0],[2,0,0],[False,True,True])\n",
    "                        model.fit(x_train, Y_train)#\n",
    "                        pred_sp = model.predict(x_validate_sp)\n",
    "                        pred_out = model.predict(x_validate_out)\n",
    "                    else: \n",
    "                        model.fit(x_train.reshape(-1,data[d][2][0]*data[d][2][1]*data[d][2][2]), Y_train)#\n",
    "                        pred_sp = model.predict(x_validate_sp.reshape(-1,data[d][2][0]*data[d][2][1]*data[d][2][2]))\n",
    "                        pred_out = model.predict(x_validate_out.reshape(-1,data[d][2][0]*data[d][2][1]*data[d][2][2]))\n",
    "                        \n",
    "\n",
    "                    LOG(d)\n",
    "                    LOG(str(w))\n",
    "                    LOG(str(wss))\n",
    "                    for i in range(len(e) - 1):\n",
    "                        LOG(e[i])                    \n",
    "                    print (d,w,wss,e[:len(e)-1])\n",
    "\n",
    "\n",
    "                    LOG(mean_squared_error(Y_validate_sp, pred_sp))\n",
    "                    LOG(mean_squared_error(Y_validate_out, pred_out))\n",
    "                    #print(mean_squared_error(Y_validate, pred))\n",
    "                    LOG('\\n')\n",
    "                else:\n",
    "                    print (\"Skip:\",d,w,wss,e[:len(e)-1])                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81daeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=co2t.CO2TreeReg(C=5500, min_samples_leaf=4,dual=False,tol = 0.0001,max_iter=10000,kernel=\"polynomial\",max_deth=3,sample_ratio=1.0, feature_ratio = 0.1,gamma=100,dropout_low=0.0,dropout_high=1.0,noise=0.,cov_dr=0.)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6d8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f02a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4041cc18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(csr_matrix(x_train.reshape(-1,data[d][2][0]*data[d][2][1]*data[d][2][2])),Y_train)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e15c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(csr_matrix(x_validate.reshape(-1,data[d][2][0]*data[d][2][1]*data[d][2][2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a58c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0acd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in model.layers_['layer_0'].estimators_['0-0-custom'].estimators_[0].trees[0].nodes:\n",
    "    print(n.p0,n.p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f492907",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in model.nodes:\n",
    "    print(n.p0,n.p1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d069348",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5386810",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in model.layers_['layer_0'].estimators_['0-0-custom'].estimators_[0].trees[1].nodes:\n",
    "    print(n.p0,n.p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers_['layer_0'].estimators_['0-0-custom'].estimators_[0].trees[0].leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b39b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers_['layer_0'].estimators_['0-0-custom'].estimators_[0].predict(x_validate.reshape(-1,data[d][2][0]*data[d][2][1]*data[d][2][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164d96c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers_['layer_0'].estimators_['0-0-custom'].estimators_[0].trees[0].predict(csr_matrix(x_validate.reshape(-1,data[d][2][0]*data[d][2][1]*data[d][2][2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d65426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers_['layer_0'].estimators_['0-0-custom'].estimators_[0].trees[0].nodes[9].stamp_sign(csr_matrix(x_validate.reshape(-1,data[d][2][0]*data[d][2][1]*data[d][2][2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe69a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a936ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31d7a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0c8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.unique(model.layers_['layer_0'].estimators_['0-0-custom'].estimators_[0].trees[0].nodes[0].stamp_sign(csr_matrix(x_train.reshape(-1,data[d][2][0]*data[d][2][1]*data[d][2][2]))),return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672f6184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k = KMeans(n_clusters=2)\n",
    "k.fit_predict(Y_train.reshape(-1,1))*2 - 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aac9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.unique(model.nodes[0].stamp_sign(csr_matrix(x_train.reshape(-1,data[d][2][0]*data[d][2][1]*data[d][2][2]))),return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e116f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
