{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "train_set = dset.MNIST(root='./data', train=True, transform=trans, download=True)\n",
    "test_set = dset.MNIST(root='./data', train=False, transform=trans)\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):   \n",
    "    def __init__(self, num=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),   \n",
    "            nn.MaxPool2d( kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 96, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),                         \n",
    "            nn.Conv2d(96, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),                         \n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d( kernel_size=2, stride=1),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(32*12*12,2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024,num),\n",
    "         \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.feature(x)\n",
    "        x = x.view(-1,32*12*12)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, data_size = None):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if data_size is not None:\n",
    "            if batch_idx*batch_size > data_size:\n",
    "                break\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "#         loss = F.nll_loss(output, target)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        train_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('\\rEpoch: {} {:.0f}%\\t     Loss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                100. * batch_idx / len(train_loader), loss.item()), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "    \n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    acc=100. * float(correct.to(torch.device('cpu')).numpy())\n",
    "    print('\\nTest result: Average loss: {:.4f}, Accuracy: {:.4f}%\\n'.format(\n",
    "        test_loss, acc / len(test_loader.dataset)))\n",
    "    \n",
    "    test_accuracy.append(acc / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 5%\t     Loss: 2.302842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8490/3364036503.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test result: Average loss: 2.3017, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 2 5%\t     Loss: 2.295021\n",
      "Test result: Average loss: 2.3015, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 3 5%\t     Loss: 2.312072\n",
      "Test result: Average loss: 2.3013, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 4 5%\t     Loss: 2.299050\n",
      "Test result: Average loss: 2.3012, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 5 5%\t     Loss: 2.318035\n",
      "Test result: Average loss: 2.3011, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 6 5%\t     Loss: 2.293981\n",
      "Test result: Average loss: 2.3009, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 7 5%\t     Loss: 2.307189\n",
      "Test result: Average loss: 2.3009, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 8 5%\t     Loss: 2.302180\n",
      "Test result: Average loss: 2.3008, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 9 5%\t     Loss: 2.310660\n",
      "Test result: Average loss: 2.3007, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 10 5%\t     Loss: 2.319592\n",
      "Test result: Average loss: 2.3006, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 11 5%\t     Loss: 2.298089\n",
      "Test result: Average loss: 2.3008, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 12 5%\t     Loss: 2.315783\n",
      "Test result: Average loss: 2.3006, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 13 5%\t     Loss: 2.305043\n",
      "Test result: Average loss: 2.3005, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 14 5%\t     Loss: 2.283313\n",
      "Test result: Average loss: 2.3001, Accuracy: 11.3500%\n",
      "\n",
      "5000 255.80986189842224\n",
      "Epoch: 1 16%\t     Loss: 2.303179\n",
      "Test result: Average loss: 2.3018, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 2 16%\t     Loss: 2.299634\n",
      "Test result: Average loss: 2.3013, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 3 16%\t     Loss: 2.311086\n",
      "Test result: Average loss: 2.3012, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 4 16%\t     Loss: 2.293794\n",
      "Test result: Average loss: 2.3009, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 5 16%\t     Loss: 2.300819\n",
      "Test result: Average loss: 2.3009, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 6 16%\t     Loss: 2.294347\n",
      "Test result: Average loss: 2.3006, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 7 16%\t     Loss: 2.317161\n",
      "Test result: Average loss: 2.3003, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 8 16%\t     Loss: 2.300287\n",
      "Test result: Average loss: 2.3001, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 9 16%\t     Loss: 2.304204\n",
      "Test result: Average loss: 2.2996, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 10 16%\t     Loss: 2.304277\n",
      "Test result: Average loss: 2.2988, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 11 16%\t     Loss: 2.290410\n",
      "Test result: Average loss: 2.2973, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 12 16%\t     Loss: 2.291096\n",
      "Test result: Average loss: 2.2936, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 13 16%\t     Loss: 2.279484\n",
      "Test result: Average loss: 2.2813, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 14 16%\t     Loss: 2.179954\n",
      "Test result: Average loss: 2.0772, Accuracy: 21.8000%\n",
      "\n",
      "10000 415.30926871299744\n",
      "Epoch: 1 80%\t     Loss: 2.307682\n",
      "Test result: Average loss: 2.3006, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 2 80%\t     Loss: 2.301063\n",
      "Test result: Average loss: 2.2978, Accuracy: 11.3500%\n",
      "\n",
      "Epoch: 3 80%\t     Loss: 0.223295\n",
      "Test result: Average loss: 0.2675, Accuracy: 92.2100%\n",
      "\n",
      "Epoch: 4 80%\t     Loss: 0.441555\n",
      "Test result: Average loss: 0.1137, Accuracy: 95.9600%\n",
      "\n",
      "Epoch: 5 80%\t     Loss: 0.084199\n",
      "Test result: Average loss: 0.0718, Accuracy: 97.6700%\n",
      "\n",
      "Epoch: 6 80%\t     Loss: 0.047415\n",
      "Test result: Average loss: 0.0593, Accuracy: 98.0000%\n",
      "\n",
      "Epoch: 7 80%\t     Loss: 0.179499\n",
      "Test result: Average loss: 0.0517, Accuracy: 98.3200%\n",
      "\n",
      "Epoch: 8 80%\t     Loss: 0.027667\n",
      "Test result: Average loss: 0.0515, Accuracy: 98.3500%\n",
      "\n",
      "Epoch: 9 80%\t     Loss: 0.066694\n",
      "Test result: Average loss: 0.0425, Accuracy: 98.6500%\n",
      "\n",
      "Epoch: 10 80%\t     Loss: 0.010610\n",
      "Test result: Average loss: 0.0473, Accuracy: 98.5600%\n",
      "\n",
      "Epoch: 11 80%\t     Loss: 0.057288\n",
      "Test result: Average loss: 0.0333, Accuracy: 98.8800%\n",
      "\n",
      "Epoch: 12 80%\t     Loss: 0.011209\n",
      "Test result: Average loss: 0.0369, Accuracy: 98.8900%\n",
      "\n",
      "Epoch: 13 80%\t     Loss: 0.010931\n",
      "Test result: Average loss: 0.0302, Accuracy: 98.9400%\n",
      "\n",
      "Epoch: 14 80%\t     Loss: 0.005059\n",
      "Test result: Average loss: 0.0302, Accuracy: 98.9400%\n",
      "\n",
      "50000 1756.6890790462494\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for sz in [5000,10000,50000]:\n",
    "    model = AlexNet()\n",
    "    #if torch.cuda.is_available():\n",
    "    #    model.cuda()\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_losses = []\n",
    "    test_losses =[]\n",
    "    test_accuracy = []\n",
    "    for epoch in range(1, 15):\n",
    "        train(epoch,sz)\n",
    "        test()\n",
    "\n",
    "    print(sz,time.time() - start_time)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4219509764.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_8490/4219509764.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1000 125.25717401504517\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1000 125.25717401504517\n",
    "3000 189.90918970108032\n",
    "5000 255.80986189842224\n",
    "10000 415.30926871299744\n",
    "50000 1756.6890790462494"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting numpy==1.19.5\n",
      "  Downloading numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.9 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.1\n",
      "    Uninstalling numpy-1.24.1:\n",
      "      Successfully uninstalled numpy-1.24.1\n",
      "Successfully installed numpy-1.19.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting torch==1.4.0\n",
      "  Downloading torch-1.4.0-cp38-cp38-manylinux1_x86_64.whl (753.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 753.4 MB 602 kB/s eta 0:00:011    |████▏                           | 97.3 MB 621 kB/s eta 0:17:36     |██████▍                         | 149.8 MB 608 kB/s eta 0:16:32     |███████▋                        | 179.4 MB 256 kB/s eta 0:37:23     |████████▍                       | 196.8 MB 53.8 MB/s eta 0:00:11     |████████▋                       | 201.7 MB 53.8 MB/s eta 0:00:11     |█████████▌                      | 223.6 MB 161 kB/s eta 0:54:48     |██████████                      | 235.3 MB 153 kB/s eta 0:56:11     |█████████████████▍              | 409.3 MB 25.3 MB/s eta 0:00:14     |█████████████████▌              | 411.4 MB 25.3 MB/s eta 0:00:14     |██████████████████▊             | 441.8 MB 283 kB/s eta 0:18:19     |████████████████████▉           | 489.3 MB 146 kB/s eta 0:29:58     |█████████████████████           | 493.7 MB 146 kB/s eta 0:29:27     |█████████████████████▌          | 507.5 MB 614 kB/s eta 0:06:40     |████████████████████████████▋   | 673.6 MB 19.1 MB/s eta 0:00:05\n",
      "\u001b[?25hInstalling collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0a0+bfe5ad2\n",
      "    Uninstalling torch-1.11.0a0+bfe5ad2:\n",
      "      Successfully uninstalled torch-1.11.0a0+bfe5ad2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.12.0a0 requires torch==1.11.0a0+bfe5ad2, but you have torch 1.4.0 which is incompatible.\n",
      "torchtext 0.12.0a0 requires torch==1.11.0a0+bfe5ad2, but you have torch 1.4.0 which is incompatible.\n",
      "torch-tensorrt 1.1.0a0 requires torch>=1.10.0+cu113<1.11.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting torchvision==0.10.0\n",
      "  Downloading torchvision-0.10.0-cp38-cp38-manylinux1_x86_64.whl (22.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.1 MB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision==0.10.0) (1.19.5)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision==0.10.0) (8.2.0)\n",
      "Collecting torch==1.9.0\n",
      "  Downloading torch-1.9.0-cp38-cp38-manylinux1_x86_64.whl (831.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 831.4 MB 18.2 MB/s eta 0:00:01    |▌                               | 12.7 MB 68.1 MB/s eta 0:00:13     |▊                               | 17.4 MB 68.1 MB/s eta 0:00:12     |███▏                            | 82.7 MB 62.9 MB/s eta 0:00:12     |█████████▊                      | 253.1 MB 37.8 MB/s eta 0:00:16     |██████████▌                     | 272.6 MB 37.8 MB/s eta 0:00:15     |████████████▋                   | 326.4 MB 28.4 MB/s eta 0:00:18     |█████████████                   | 340.1 MB 28.4 MB/s eta 0:00:18     |█████████████▉                  | 360.1 MB 177 kB/s eta 0:44:18     |██████████████▋                 | 378.5 MB 177 kB/s eta 0:42:34     |███████████████▏                | 394.9 MB 177 kB/s eta 0:41:02     |███████████████████▋            | 510.4 MB 29.1 MB/s eta 0:00:12     |█████████████████████▌          | 559.0 MB 44.8 MB/s eta 0:00:07     |████████████████████████▉       | 645.0 MB 31.1 MB/s eta 0:00:06     |██████████████████████████▉     | 695.9 MB 22.0 MB/s eta 0:00:07\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch==1.9.0->torchvision==0.10.0) (4.0.1)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.4.0\n",
      "    Uninstalling torch-1.4.0:\n",
      "      Successfully uninstalled torch-1.4.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.12.0a0\n",
      "    Uninstalling torchvision-0.12.0a0:\n",
      "      Successfully uninstalled torchvision-0.12.0a0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.12.0a0 requires torch==1.11.0a0+bfe5ad2, but you have torch 1.9.0 which is incompatible.\n",
      "torch-tensorrt 1.1.0a0 requires torch>=1.10.0+cu113<1.11.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.9.0 torchvision-0.10.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
