{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "train_ds = pandas.read_csv(\"youtube/PM_youtube_train.csv\")\n",
    "test_ds = pandas.read_csv(\"youtube/PM_youtube_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "label_enc.fit(train_ds['subgroup'])\n",
    "y_train = label_enc.transform(train_ds['subgroup']) \n",
    "y_test = label_enc.transform(test_ds['subgroup'])\n",
    "\n",
    "y_train += 1\n",
    "y_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "X_train = train_ds.as_matrix()[:,5:].astype(float)\n",
    "X_test = test_ds.as_matrix()[:,5:].astype(float)\n",
    "\n",
    "mm = make_pipeline(MinMaxScaler(), Normalizer())\n",
    "mm.fit(X_train)\n",
    "\n",
    "X_train = mm.transform(X_train)\n",
    "X_test = mm.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "for d in range(3,15,1):\n",
    "    for f in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8]:\n",
    "        model = RandomForestClassifier(n_estimators=100, max_features=f,max_depth=d,criterion='entropy',class_weight='balanced')\n",
    "        scores = cross_val_score(model, X_train, y_train, scoring='f1_macro', cv=5, n_jobs=-1)\n",
    "        print (d,f,np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "model = RandomForestClassifier(n_estimators=100, max_features=0.5,max_depth=14,criterion='entropy',class_weight='balanced')\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "pred_y = model.predict(X_test)\n",
    "scores = f1_score(pred_y,y_test,average=None)\n",
    "print (np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "for d in range(2,5,1):\n",
    "    model = XGBClassifier(max_depth=d)\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring='f1_macro', cv=5, n_jobs=-1)\n",
    "    print (d,scores,np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(max_depth=5,use_label_encoder=False)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "pred_y = model.predict(X_test)\n",
    "scores = f1_score(pred_y,y_test,average=None)\n",
    "print (np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from thundersvm import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#for gamma in [100.]:\n",
    "gamma = 0\n",
    "for c in [5000]:\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    itr = 0\n",
    "    res = []\n",
    "    res2 = []\n",
    "    for train, test in kf.split(X_train):       \n",
    "        X_train_ = X_train[train]\n",
    "        X_test_ = X_train[test]\n",
    "        y_train_ = y_train[train]\n",
    "        y_test_ = y_train[test]        \n",
    "        cl = SVC(C=c,kernel='poly',tol=0.0001,max_iter=1000000,degree=4,verbose=False,class_weight = 'balanced')\n",
    "        #cl = LinearSVC(C=c,tol=0.0001,max_iter=1000000, class_weight = 'balanced')\n",
    "\n",
    "        cl.fit(X_train_,y_train_)#,sample_weights=deltas)\n",
    "        y_pred = cl.predict(X_test_)\n",
    "        y_pred2 = cl.predict(X_train_)\n",
    "        res.append(f1_score(y_test_,y_pred,average=None)) \n",
    "        res2.append(f1_score(y_train_,y_pred2,average=None)) \n",
    "        print (res,res2)\n",
    "        \n",
    "\n",
    "    res = np.asarray(res)   \n",
    "    res2 = np.asarray(res2) \n",
    "    print(gamma,c,res.mean(),res.std())\n",
    "    print(gamma,c,res2.mean(),res2.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 3000 0.8355805345573482 0.10631811197292429\n",
    "0 3000 0.9076560062560901 0.022493988147552536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train my own KF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "import CO2_tree as co2t\n",
    "import CO2_forest as co2f\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "tree_deth = [2,3,4]\n",
    "sratios = [0.]\n",
    "sratios2 = [1.0]\n",
    "fratios = [0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "C = [5000]\n",
    "\n",
    "\n",
    "\n",
    "for d in tree_deth:\n",
    "    for sratio in sratios:\n",
    "        for sratio2 in sratios2:\n",
    "            for fratio in fratios:\n",
    "                for gm in [5]:\n",
    "                    for ns in [0.]:                \n",
    "                        kf = KFold(n_splits=5, shuffle=True)\n",
    "                        itr = 0\n",
    "                        res = []\n",
    "                        res2 = []\n",
    "                        for train, test in kf.split(X_train):       \n",
    "                            X_train_ = csr_matrix(X_train[train])\n",
    "                            X_test_ = csr_matrix(X_train[test])\n",
    "                            y_train_ = y_train[train]\n",
    "                            y_test_ = y_train[test]   \n",
    "                            \n",
    "                            \n",
    "                            #cl = SVC(C=c,kernel='rbf',tol=0.0001,max_iter=1000,gamma=gamma,verbose=False)\n",
    "                            cl = co2f.CO2_forest(C=5000, dual=False,tol = 0.0001,max_iter=100000000,kernel='polynomial',max_deth=d,n_jobs=5,sample_ratio=1.0, feature_ratio = fratio,n_estimators=100,gamma=gm,dropout_low=sratio,dropout_high=sratio2,noise=ns,cov_dr=0.,criteria='gain')\n",
    "                            #cl = LinearSVC(C=c,tol=0.0001,max_iter=1000)\n",
    "\n",
    "                            cl.fit(X_train_,y_train_)\n",
    "                            y_pred = cl.predict(X_test_)\n",
    "                            y_pred2 = cl.predict(X_train_)\n",
    "                            res.append(f1_score(y_test_,y_pred,average=None)) \n",
    "                            res2.append(f1_score(y_train_,y_pred2,average=None)) \n",
    "                            #print (res,res2)\n",
    "\n",
    "                        res = numpy.asarray(res)   \n",
    "                        res2 = numpy.asarray(res2) \n",
    "                        print(\"Test:\",d,gm,fratio,res.mean(),res.std())\n",
    "                        print(\"Train:\", d,gm,fratio,res2.mean(),res2.std())\n",
    "                        #print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/notebooks/thunder/thundersvm/CO2_forest.py:217: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  r2 = cov(numpy.hstack(cprobs[:,:,layer] for layer in range(1,cprobs.shape[2])))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR orig test result: 0.057558945908460446 C: 0.1 r2 before: 4.250286347637379 r2 after: 3.416959254332953\n",
      "LR noised test result: 0.05963938973647709 C: 0.1 noise: 0.2 r2 before: 4.250286347637379 r2 after: 2.9604719741914853\n",
      "LR balanced noise test result: 0.05894590846047154 C: 1.0 noise: 0.3 r2 before: 4.250286347637379 r2 after: 2.5449787395965333\n",
      "LR naive pruning test result: 0.061026352288488184 C: 1.0 pruning: 0.1 r2 before: 4.250286347637379 r2 after: 2.9735177613459434\n",
      "LR l2-norm pruning test result: 0.05963938973647709 C: 0.1 pruning: 0.4 r2 before: 4.250286347637379 r2 after: 3.318998572795651 instability before: 94.22940617247062 instability after: 9.21100065827613\n"
     ]
    }
   ],
   "source": [
    "import nlopt\n",
    "import numpy\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import CO2_tree as co2t\n",
    "import CO2_forest as co2f\n",
    "from scipy.sparse import csr_matrix\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(20):\n",
    "    print (i)\n",
    "    cl = co2f.CO2_forest(C=5000, dual=False,tol = 0.0001,max_iter=2000000000,kernel='polynomial',max_deth=3,n_jobs=10,sample_ratio=1.0, feature_ratio = 0.3,n_estimators=10,gamma=5,dropout_low=0.0,dropout_high=1.0,noise=0.,cov_dr=100.,criteria='gain')\n",
    "    cl.fit(csr_matrix(X_train), y_train, csr_matrix(X_test),y_test)\n",
    "    y_pred_train = cl.predict(csr_matrix(X_train))\n",
    "    y_pred = cl.predict(csr_matrix(X_test))\n",
    "    rs_local_test = accuracy_score(y_test,y_pred)\n",
    "    rs_local_train = accuracy_score(y_train,y_pred_train)\n",
    "    #results.append([probs,r2,r3,rs_local_train - rs_local_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlopt\n",
    "import numpy\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import CO2_tree as co2t\n",
    "import CO2_forest as co2f\n",
    "from scipy.sparse import csr_matrix\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "for _ in range(30):\n",
    "    cl = co2f.CO2_forest(C=5000, dual=False,tol = 0.0001,max_iter=2000000000,kernel='polynomial',max_deth=3,n_jobs=10,sample_ratio=1.0, feature_ratio = 0.3,n_estimators=10,gamma=5,dropout_low=0.0,dropout_high=1.0,noise=0.,cov_dr=100.,criteria='gain')\n",
    "    probs, r2,r3 = cl.fit(csr_matrix(X_train), y_train, csr_matrix(X_test),y_test)\n",
    "    ratios = (1. / probs).sum(axis=1)\n",
    "    idx = numpy.argmax(ratios)\n",
    "    y_pred_train = cl.predict(csr_matrix(X_train))\n",
    "    y_pred = cl.predict(csr_matrix(X_test))\n",
    "    rs_local_test = accuracy_score(y_test,y_pred)\n",
    "    rs_local_train = accuracy_score(y_train,y_pred_train) \n",
    "    print (\"Drop:\", idx)\n",
    "    print (rs_local_train - rs_local_test)\n",
    "    cl.trees.pop(idx)\n",
    "    y_pred_train = cl.predict(csr_matrix(X_train))\n",
    "    y_pred = cl.predict(csr_matrix(X_test))\n",
    "    rs_local_test = accuracy_score(y_test,y_pred)\n",
    "    rs_local_train = accuracy_score(y_train,y_pred_train)    \n",
    "    print (rs_local_train - rs_local_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1. / probs).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = cl.predict(csr_matrix(X_train))\n",
    "y_pred = cl.predict(csr_matrix(X_test))\n",
    "rs_local_test = accuracy_score(y_test,y_pred)\n",
    "rs_local_train = accuracy_score(y_train,y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_local_train - rs_local_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.trees.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = cl.predict(csr_matrix(X_train))\n",
    "y_pred = cl.predict(csr_matrix(X_test))\n",
    "rs_local_test = accuracy_score(y_test,y_pred)\n",
    "rs_local_train = accuracy_score(y_train,y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_local_train - rs_local_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_local_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for r in results:\n",
    "    x.append((r[0].sum(axis=0)*r[0].sum(axis=0)).sum())\n",
    "    y.append(r[3])\n",
    "\n",
    "plt.scatter(x, y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for r in results:\n",
    "    x.append((r[0]*r[0]).sum())\n",
    "    y.append(r[3])\n",
    "\n",
    "plt.scatter(x, y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for r in results:\n",
    "    x.append(r[1])\n",
    "    y.append(r[3])\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for r in results:\n",
    "    x.append(r[2])\n",
    "    y.append(r[3])\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for r in results:\n",
    "    x.append((1. / r[0]).sum())\n",
    "    y.append(r[3])\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for r in results:\n",
    "    x.append((1. / r[0].sum(axis=0)).sum())\n",
    "    y.append(r[3])\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for r in results:\n",
    "    x.append((1. / r[0]).sum() * r[1])\n",
    "    y.append(r[3])\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlopt\n",
    "import numpy\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import CO2_tree as co2t\n",
    "import CO2_forest as co2f\n",
    "from scipy.sparse import csr_matrix\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "cl = co2f.CO2_forest(C=5000, dual=False,tol = 0.0001,max_iter=2000000000,kernel='polynomial',max_deth=3,n_jobs=2,sample_ratio=1.0, feature_ratio = 0.3,n_estimators=2,gamma=5,dropout_low=0.0,dropout_high=1.0,noise=0.,cov_dr=100.,criteria='gain')\n",
    "\n",
    "def genRatios(rest,step, depth):\n",
    "    if depth > 1:\n",
    "        if rest > 0:\n",
    "            for val in numpy.arange(0.,rest+ 0.000001,step):\n",
    "                #print(\"(\",rest,val,depth,\")\")\n",
    "                for rest_ in genRatios(rest - val,step,depth - 1):\n",
    "                    yield [val] + rest_ \n",
    "        else:\n",
    "            yield []\n",
    "    else:\n",
    "        yield [rest]\n",
    "\n",
    "def weighter(tree,forest,w):\n",
    "    t = forest.trees[tree]\n",
    "    t.estimateChunkWeights(w[tree])\n",
    "    return t\n",
    "\n",
    "cl.fit(csr_matrix(X_train), y_train)\n",
    "ratios_ = numpy.zeros((2,))\n",
    "for i in numpy.arange(0,1.05,0.05):\n",
    "    ratios_[0] = i\n",
    "    ratios_[1] = 1. - i\n",
    "    cl.trees = Parallel(n_jobs=cl.n_jobs,backend=\"multiprocessing\")(delayed(weighter)(i,cl,ratios_) for i in range(cl.n_estimators))\n",
    "    y_pred = cl.predict(csr_matrix(X_test))\n",
    "    rs_local = accuracy_score(y_test,y_pred)\n",
    "    print (i,1. - i, 1. - rs_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_max_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_max_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cov matrix and biases\n",
    "from numpy import corrcoef\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "r_ = numpy.zeros((len(cl.trees), len(cl.trees))) \n",
    "for i in range(len(cl.trees)):\n",
    "    for j in range(len(cl.trees)): \n",
    "        t1 = cl.trees[i].getCounts()\n",
    "        t2 = cl.trees[j].getCounts()\n",
    "        if len(t1.shape) != 2: \n",
    "            for k in range(t1.shape[0]): \n",
    "                if t1[k].shape[0] < 3*X_train.shape[0]:\n",
    "                    tmp = numpy.zeros((3*X_train.shape[0],))\n",
    "                    tmp[:t1[k].shape[0]] = t1[k]\n",
    "                    t1[k] = tmp    \n",
    "            t1 = numpy.vstack(t1)        \n",
    "        if len(t2.shape) != 2:\n",
    "            for k in range(t2.shape[0]): \n",
    "                if t2[k].shape[0] < 3*X_train.shape[0]:\n",
    "                    tmp = numpy.zeros((3*X_train.shape[0],))\n",
    "                    tmp[:t2[k].shape[0]] = t2[k]\n",
    "                    t2[k] = tmp              \n",
    "            t2 = numpy.vstack(t2)\n",
    "        \n",
    "        counts = numpy.vstack([t1, t2])\n",
    "        corr = corrcoef(counts)\n",
    "\n",
    "        tmp = []\n",
    "        for k in range(corr.shape[0]):\n",
    "            for l in range(corr.shape[1]):\n",
    "                if (k > len(t1) and l < len(t1)) or (k < len(t1) and l > len(t1)):\n",
    "                    tmp.append(corr[k,l])\n",
    "        if i != j:            \n",
    "            r_[i,j] = numpy.asarray(tmp).mean()            \n",
    "\n",
    "probs = []\n",
    "for t in cl.trees:\n",
    "    probs.append(numpy.abs(numpy.asarray(t.getProbs()) - 1. / pow(2, cl.max_deth)).mean())\n",
    "biases = numpy.asarray(probs)    \n",
    "#all_counts = numpy.vstack(counts)\n",
    "#r_ = corrcoef(all_counts)\n",
    "#r_ = []\n",
    "#counter_h = 0\n",
    "\n",
    "#for i in range(len(counts)):\n",
    "#    rl = {}\n",
    "#    for j in range(len(counts[i])): \n",
    "#        counter_w = 0\n",
    "#        for k in range(len(counts)):\n",
    "#            rline = []\n",
    "#            for l in range(len(counts[k])):\n",
    "#                rline.append(r[counter_h, counter_w])\n",
    "#                counter_w += 1\n",
    "#            if k not in rl:\n",
    "#                rl[k] = []\n",
    "#            rl[k].append(rline)\n",
    "#        counter_h += 1\n",
    "#    tmp = []    \n",
    "#    for k in range(len(counts)):\n",
    "#        tmp.append(numpy.concatenate(rl[k]).mean())\n",
    "#    r_.append(tmp)    \n",
    "#r_ = numpy.asarray(r_)                \n",
    "print ('biases')\n",
    "print (biases)\n",
    "\n",
    "r_[r_==1.0] = 0.\n",
    "print ('r')\n",
    "print(r_)\n",
    "\n",
    "P = cl.get_err_matrix(csr_matrix(X_train), y_train,use_weight=False)            \n",
    "G = numpy.dot(P,numpy.transpose(P))\n",
    "G = G / G.max()\n",
    "\n",
    "print (\"G:\",G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = numpy.zeros((len(cl.trees), len(cl.trees))) \n",
    "for i in range(len(cl.trees)):\n",
    "    for j in range(len(cl.trees)): \n",
    "        t1 = cl.trees[i].getCounts()\n",
    "        t2 = cl.trees[j].getCounts()\n",
    "\n",
    "        if len(t1.shape) != 2: \n",
    "            for k in range(t1.shape[0]): \n",
    "                if t1[k].shape[0] < 3*X_train.shape[0]:\n",
    "                    tmp = numpy.zeros((3*X_train.shape[0],))\n",
    "                    tmp[:t1[k].shape[0]] = t1[k]\n",
    "                    t1[k] = tmp    \n",
    "            t1 = numpy.vstack(t1)        \n",
    "        if len(t2.shape) != 2:\n",
    "            for k in range(t2.shape[0]): \n",
    "                if t2[k].shape[0] < 3*X_train.shape[0]:\n",
    "                    tmp = numpy.zeros((3*X_train.shape[0],))\n",
    "                    tmp[:t2[k].shape[0]] = t2[k]\n",
    "                    t2[k] = tmp              \n",
    "            t2 = numpy.vstack(t2)\n",
    "\n",
    "        t1 = t1[:,:X_train.shape[0]] + t1[:,X_train.shape[0]:2*X_train.shape[0]] + t1[:,2*X_train.shape[0]:]\n",
    "        t2 = t2[:,:X_train.shape[0]] + t2[:,X_train.shape[0]:2*X_train.shape[0]] + t2[:,2*X_train.shape[0]:] \n",
    "        \n",
    "        #t1[t1 > 1] = 1.\n",
    "        #t2[t2 > 1] = 1.\n",
    "        \n",
    "        counts = numpy.vstack([t1, t2])\n",
    "        corr = corrcoef(counts)\n",
    "\n",
    "        tmp = []\n",
    "        for k in range(corr.shape[0]):\n",
    "            for l in range(corr.shape[1]):\n",
    "                if (k > len(t1) and l < len(t1)) or (k < len(t1) and l > len(t1)):\n",
    "                    tmp.append(corr[k,l])\n",
    "        if i != j:            \n",
    "            r2[i,j] = numpy.asarray(tmp).mean()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2[r2 < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "pearsonr(global_max_w,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(global_max_w,r_.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(global_max_w,r2.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(global_max_w,P.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(global_max_w,G.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in cl.trees:\n",
    "    print(numpy.asarray(t.getProbs()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cl.trees[5].getCounts())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cl.trees[5].getCounts())[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test,y_pred,average=None)\n",
    "#4/poly/0.5 array([0.95306859, 0.88      , 0.95329874])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_train,y_predt,average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([0.95286439, 0.88590604, 0.95427729]) (3, poly, deg 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(X_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
